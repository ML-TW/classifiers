{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineaire Regressie in Python\n",
    "## 1.4 Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De Normal Equation heeft enkele beperkingen in gebruik, met name voor heel grote datasets:\n",
    "\n",
    "- voor deze analytische afleiding van de regressiecoefficienten moeten we de inverse nemen over $m \\times m$-matrix waarbij $m$ het aantal features/kolommen is in de input matrix $X$. Het bepalen van een inverse is een functie van de orde $O(n^3)$, dus bij grote waarden van $m$ wordt het te kostbaar om deze aanpak te gebruiken. \n",
    "- als datasets niet in het intern geheugen passen door een te groot aantal rijen wordt het inefficient.\n",
    "- de Normal Equation werkt voor zover bekend alleen voor de standaard least squares kostenfunctie. We gaan binnenkort kijken naar andere kostenfuncties zoals logistische kostenfuncties waarvoor de Normal Equation niet werkt.\n",
    "\n",
    "Een andere populaire aanpak om een kostenfunctie te optimaliseren is Gradient Descent. Volgens deze methode worden de coefficienten iteratief met kleine stapjes bijgesteld in de richting van een lagere waarde voor de kostenfunctie. Om de richting van de coefficienten te bepalen worden partial derivatives van de kostenfunctie gebruikt. Het voordeel is dat deze aanpak generiek bruikbaar is voor heel veel problemen en met grote hoeveelheden data. Een nadeel is dat Gradient Descent een lokaal minimum kan vinden in plaats van een globaal minimum. Daar komen we in een latere week op terug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Desscent update functies\n",
    "\n",
    "Het basis voor Gradient Descent is om de coefficienten stapsgewijs in de richting van het minimum te verplaatsen. We gebruiken daarvoor een algemene update rule, waarin $\\theta_j$ de coefficient is die wordt geupdate, $J(\\theta)$ de kostenfunctie die geparameteriseerd is door $\\theta$ en $\\alpha$ de learning rate die bepaalt hoe groot de stappen zijn waarmee geleerd wordt:\n",
    "\n",
    "$$ \\theta_j = \\theta_j - \\alpha \\frac{\\delta}{\\delta \\theta_j}J(\\theta) $$\n",
    "\n",
    "In deze update rule kunnen we het minteken verklaren door te kijken naar de afgeleide. Als de afgeleide positief is, dan ligt het minimum bij een lagere waarde van de coefficient en omgekeerd. De learning rate $\\alpha$ bepaalt de grootte van de update stap. We gaan de learning rate later in detail bestuderen, voor nu geven we bij deze code een passende waarde voor de learning rate. \n",
    "\n",
    "We gaan eerst exerimenteren met de kostenfunctie $J(\\theta)$ die we eerder hebben gebruikt om een lineaire regressielijn te fitten met een enkele onafhankelijke variable $x$. De aanpassing van de kostenfunctie met $\\frac{1}{2n}$ maakt voor het optimalisatieprobleem niet uit, maar levert na het differentieren een nettere updaterule op.\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2n} \\sum_{i = 1}^n (\\widehat{y^{(i)}} - y^{(i)})^2 = \\frac{1}{2n} \\sum_{i = 1}^n (\\theta_1 \\cdot x^{(i)} + \\theta_0 - y^{(i)})^2 $$  \n",
    "\n",
    "Door het toepassen van de chain-rule voor partitieel afgeleiden krijgen we dan:\n",
    "\n",
    "$$ \\frac{\\delta J(\\theta)}{\\delta \\theta_0} = \\frac{1}{n} \\sum_{i=1}^n (\\theta_1 \\cdot x^{(i)} + \\theta_0 - y^{(i)}) \\cdot 1 $$\n",
    "\n",
    "$$ \\frac{\\delta J(\\theta)}{\\delta \\theta_1} = \\frac{1}{n} \\sum_{i=1}^n (\\theta_1 \\cdot x^{(i)} + \\theta_0 - y^{(i)}) \\cdot x^{(i)} $$\n",
    "\n",
    "De update rules worden dan:\n",
    "\n",
    "$$ \\theta_0 := \\theta_0 - \\alpha \\cdot \\frac{1}{n} \\sum_{i=1}^n (\\theta_1 \\cdot x^{(i)} + \\theta_0 - y^{(i)}) $$\n",
    "$$ \\theta_1 := \\theta_1 - \\alpha \\cdot \\frac{1}{n} \\sum_{i=1}^n (\\theta_1 \\cdot x^{(i)} + \\theta_0 - y^{(i)}) \\cdot x^{(i)} $$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementatie van Gradient Descent\n",
    "\n",
    "We laden wederom eerst de data en prepareren een matrix $X$ met input data en $y$ met de te verklaren variabele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wijnen = pd.read_csv('winequality-red.csv', delimiter=';')\n",
    "\n",
    "wijnen['bias'] = 1\n",
    "X = wijnen[['bias', 'alcohol']].as_matrix()\n",
    "y = wijnen.quality.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daarnaast hebben we een vector $\\theta$ nodig met coefficienten. In dit geval kunnen we alle coefficienten initialiseren op 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "theta = np.zeros((2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zullen eerst een eenvoudige uitwerking laten zien waarmee we de kostenfunctie berekenen over de trainingsset. De eenvoudige uitwerking gebruikt een `for`-loop om de kosten te verhogen met de kwadratische afwijking van een trainingspaar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeUpdate(X, y):\n",
    "    update0 = 0\n",
    "    update1 = 0\n",
    "    for xi, yi in zip(X, y):\n",
    "        y_hat = xi[1] * theta[1] + theta[0]\n",
    "        diff = (y_hat - yi)\n",
    "        update0 -= diff\n",
    "        update1 -= diff * xi[1]\n",
    "    return update0 / len(X), update1 / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.6360225140712945, 59.153700229309955)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeUpdate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vervolgens kunnen we iteratief de update over de hele set berekenen en de coefficienten in $\\theta$ daarmee updaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.86411136  0.36187335]\n",
      "CPU times: user 1min 4s, sys: 2.34 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alpha = 0.01\n",
    "theta = np.zeros((2))\n",
    "for iter in range(50000):\n",
    "    update0, update1 = computeUpdate(X, y)\n",
    "    theta[0] += alpha * update0\n",
    "    theta[1] += alpha * update1\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien direct 2 problemen met Gradient Descent. We krijgen een benadering van de meest optimale coefficienten en het model convergeert heel langzaam. We komen later terug op mogelijke verbeteringen. Voor de duidelijkheid hebben we voor nu op eenvoudig leesbare code gefocust, we kunnen de code een stuk efficienter maken als we deze herschrijven als matrix vermenervuldigingen met Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeUpdate2(X, y):\n",
    "    y_hat = np.dot(X, theta)\n",
    "    costs = y_hat - y\n",
    "    update0 = -np.sum(costs) / len(costs)\n",
    "    update1 = -np.sum(costs * X[:, 1]) / len(costs)\n",
    "    return update0, update1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dat het qua verwerkingstijd heel veel uitmaakt hoe Gradient Descent wordt geimplementeerd. Met matrix producten gaat het ca. 80x sneller. Op een soortgelijke manier zijn er vele andere optimalisaties voor een snellere verwerking mogelijk, maar het principe van gradient descent blijft altijd hetzelfde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.86411136  0.36187335]\n",
      "CPU times: user 721 ms, sys: 0 ns, total: 721 ms\n",
      "Wall time: 721 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alpha = 0.01\n",
    "theta = np.zeros((2))\n",
    "for iter in range(50000):\n",
    "    update0, update1 = computeUpdate2(X, y)\n",
    "    theta[0] += alpha * update0\n",
    "    theta[1] += alpha * update1\n",
    "print(theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
